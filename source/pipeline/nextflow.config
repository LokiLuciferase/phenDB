

params {
    inputfolder            = ''
    modelfolder            = "${System.getenv()['PHENDB_MODEL_DIR']}"
    kronafolder            = "${System.getenv()['PHENDB_KRONA_DIR']}"
    workdir                = ''
    max_bin_size           = 30000000

    hmmdb                  = "${System.getenv()['PHENDB_ENOG_NAMES_FILE']}"
    annotation_strategy    = "${System.getenv()['PHENDB_ANNOTATION_STRATEGY']}"

    get_explanations       = true
    shap_n_features        = 10
    shap_n_samples         = 4000
    phenotrex_memory       = "5000.MB"
    phenotrex_dependencies = "${System.getenv()['BASEDIR']}/source/pipeline/trait_dependencies.tsv"
    description_file       = "${System.getenv()['BASEDIR']}/source/pipeline/trait_descriptions.txt"
    omit_nodes             = ""

    max_memory             = "30.GB"
    max_cpus               = 8
}

profiles {

    standard {
        process.executor = 'local'
    }

    cluster {
        process.executor = 'slurm'
        trace.enabled    = 'true'
        trace.file       = 'phenDB_trace.txt'
    }

}

executor {
    $local {
        cpus = params.max_cpus
        memory = params.max_memory
    }
}

process {
    withLabel: prediction {
        if (params.get_explanations) {
          maxForks = 1  // don't risk running into swap with parallel SHAP of large models
        }
        memory = params.phenotrex_memory
        cpus = 1
        errorStrategy = { task.exitStatus in [104,134,136,137,138,139,143] ? 'retry' : 'terminate' }
    }
}